{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "318cf9b7-a570-4995-9ace-d8855ce0baa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv(\"D:/recomendation/preprocessed2.csv\")\n",
    "\n",
    "# Strip trailing spaces in Season column\n",
    "data['Season'] = data['Season'].str.rstrip()\n",
    "\n",
    "# Drop unnecessary columns\n",
    "if 'Unnamed: 0' in data.columns:\n",
    "    del data['Unnamed: 0']\n",
    "\n",
    "# Convert DataFrame to list of lists for your custom tree\n",
    "training_data = data.values.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cd31867-618e-436b-9cf2-16d509076be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "header = ['State_Name', 'District_Name', 'Season', 'Crop']\n",
    "\n",
    "def class_counts(Data):\n",
    "    counts = {}\n",
    "    for row in Data:\n",
    "        label = row[-1]\n",
    "        counts[label] = counts.get(label, 0) + 1\n",
    "    return counts\n",
    "\n",
    "class Question:\n",
    "    def __init__(self, column, value):\n",
    "        self.column = column\n",
    "        self.value = value\n",
    "    def match(self, example):\n",
    "        return example[self.column] == self.value\n",
    "    def __repr__(self):\n",
    "        return f\"Is {header[self.column]} == {self.value}?\"\n",
    "\n",
    "def unique_vals(Data, col):\n",
    "    return set([row[col] for row in Data])\n",
    "\n",
    "def partition(Data, question):\n",
    "    true_rows, false_rows = [], []\n",
    "    for row in Data:\n",
    "        if question.match(row):\n",
    "            true_rows.append(row)\n",
    "        else:\n",
    "            false_rows.append(row)\n",
    "    return true_rows, false_rows\n",
    "\n",
    "def gini(Data):\n",
    "    counts = class_counts(Data)\n",
    "    impurity = 1\n",
    "    for lbl in counts:\n",
    "        prob_of_lbl = counts[lbl] / float(len(Data))\n",
    "        impurity -= prob_of_lbl**2\n",
    "    return impurity\n",
    "\n",
    "def info_gain(left, right, current_uncertainty):\n",
    "    p = float(len(left)) / (len(left) + len(right))\n",
    "    return current_uncertainty - p*gini(left) - (1-p)*gini(right)\n",
    "\n",
    "def find_best_split(Data):\n",
    "    best_gain = 0\n",
    "    best_question = None\n",
    "    current_uncertainty = gini(Data)\n",
    "    n_features = len(Data[0]) - 1\n",
    "    for col in range(n_features):\n",
    "        values = unique_vals(Data, col)\n",
    "        for val in values:\n",
    "            question = Question(col, val)\n",
    "            true_rows, false_rows = partition(Data, question)\n",
    "            if len(true_rows) == 0 or len(false_rows) == 0:\n",
    "                continue\n",
    "            gain = info_gain(true_rows, false_rows, current_uncertainty)\n",
    "            if gain > best_gain:\n",
    "                best_gain, best_question = gain, question\n",
    "    return best_gain, best_question\n",
    "\n",
    "class Leaf:\n",
    "    def __init__(self, Data):\n",
    "        self.predictions = class_counts(Data)\n",
    "\n",
    "class Decision_Node:\n",
    "    def __init__(self, question, true_branch, false_branch):\n",
    "        self.question = question\n",
    "        self.true_branch = true_branch\n",
    "        self.false_branch = false_branch\n",
    "\n",
    "def build_tree(Data):\n",
    "    gain, question = find_best_split(Data)\n",
    "    if gain == 0:\n",
    "        return Leaf(Data)\n",
    "    true_rows, false_rows = partition(Data, question)\n",
    "    true_branch = build_tree(true_rows)\n",
    "    false_branch = build_tree(false_rows)\n",
    "    return Decision_Node(question, true_branch, false_branch)\n",
    "\n",
    "def classify(row, node):\n",
    "    if isinstance(node, Leaf):\n",
    "        return node.predictions\n",
    "    if node.question.match(row):\n",
    "        return classify(row, node.true_branch)\n",
    "    else:\n",
    "        return classify(row, node.false_branch)\n",
    "\n",
    "def print_leaf(counts):\n",
    "    total = sum(counts.values())*1.0\n",
    "    probs = {}\n",
    "    for lbl in counts.keys():\n",
    "        probs[lbl] = str(int(counts[lbl]/total * 100)) + \"%\"\n",
    "    return probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f887df83-8c53-4712-ba21-59d48884660f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model_final = build_tree(training_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74c45a32-52bc-4095-8195-24883fd075fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arhar/Tur : 7%\n",
      "Jute : 9%\n",
      "Maize : 4%\n",
      "Mesta : 9%\n",
      "Other Kharif pulses : 5%\n",
      "Sesamum : 8%\n",
      "Small millets : 5%\n",
      "Blackgram : 0%\n",
      "Niger seed : 0%\n",
      "Ragi : 8%\n",
      "Sunflower : 4%\n",
      "Dry ginger : 2%\n",
      "Horse-gram : 6%\n",
      "Jowar : 1%\n",
      "Moong(Green Gram) : 8%\n",
      "Rice : 2%\n",
      "Urad : 8%\n",
      "Groundnut : 3%\n",
      "Sannhamp : 2%\n",
      "Potato : 0%\n",
      "Sweet potato : 0%\n"
     ]
    }
   ],
   "source": [
    "# Example input\n",
    "state = \"Bihar\"\n",
    "district = \"Patna\"\n",
    "season = \"Kharif\"\n",
    "\n",
    "testing_data = [[state, district, season]]\n",
    "\n",
    "for row in testing_data:\n",
    "    Predict_dict = print_leaf(classify(row, dt_model_final))\n",
    "\n",
    "# Display predictions\n",
    "for key, value in Predict_dict.items():\n",
    "    print(key, \":\", value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d5d9b41-f75f-42f0-9141-7f91681660fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded preprocessed2.csv\n",
      "Building the decision tree...\n",
      "Tree built successfully.\n",
      "Custom tree model saved to models/custom_decision_tree.pkl\n",
      "Model loaded successfully from file.\n",
      "\n",
      "--- Making a prediction with the loaded model ---\n",
      "Prediction for input: ['Bihar', 'Patna', 'Kharif']\n",
      "  Arhar/Tur: 7%\n",
      "  Jute: 9%\n",
      "  Maize: 4%\n",
      "  Mesta: 9%\n",
      "  Other Kharif pulses: 5%\n",
      "  Sesamum: 8%\n",
      "  Small millets: 5%\n",
      "  Blackgram: 0%\n",
      "  Niger seed: 0%\n",
      "  Ragi: 8%\n",
      "  Sunflower: 4%\n",
      "  Dry ginger: 2%\n",
      "  Horse-gram: 6%\n",
      "  Jowar: 1%\n",
      "  Moong(Green Gram): 8%\n",
      "  Rice: 2%\n",
      "  Urad: 8%\n",
      "  Groundnut: 3%\n",
      "  Sannhamp: 2%\n",
      "  Potato: 0%\n",
      "  Sweet potato: 0%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import pickle # <-- 1. Import the pickle library\n",
    "import os\n",
    "\n",
    "# --- Setup ---\n",
    "# Create a models directory if it doesn't exist\n",
    "if not os.path.exists('models'):\n",
    "    os.makedirs('models')\n",
    "\n",
    "# --- Data Loading ---\n",
    "try:\n",
    "    data = pd.read_csv(\"D:/recomendation/preprocessed2.csv\")\n",
    "    print(\"Successfully loaded preprocessed2.csv\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'preprocessed2.csv' not found. Please place it in the same directory.\")\n",
    "    exit()\n",
    "\n",
    "# --- Data Preparation ---\n",
    "# Strip trailing spaces in Season column\n",
    "data['Season'] = data['Season'].str.rstrip()\n",
    "\n",
    "# Drop unnecessary columns\n",
    "if 'Unnamed: 0' in data.columns:\n",
    "    del data['Unnamed: 0']\n",
    "\n",
    "# Convert DataFrame to list of lists for your custom tree\n",
    "training_data = data.values.tolist()\n",
    "header = ['State_Name', 'District_Name', 'Season', 'Crop']\n",
    "\n",
    "\n",
    "# --- Decision Tree Classes and Functions (Your Code) ---\n",
    "\n",
    "def class_counts(Data):\n",
    "    counts = {}\n",
    "    for row in Data:\n",
    "        label = row[-1]\n",
    "        counts[label] = counts.get(label, 0) + 1\n",
    "    return counts\n",
    "\n",
    "class Question:\n",
    "    def __init__(self, column, value):\n",
    "        self.column = column\n",
    "        self.value = value\n",
    "    def match(self, example):\n",
    "        return example[self.column] == self.value\n",
    "    def __repr__(self):\n",
    "        return f\"Is {header[self.column]} == {self.value}?\"\n",
    "\n",
    "def unique_vals(Data, col):\n",
    "    return set([row[col] for row in Data])\n",
    "\n",
    "def partition(Data, question):\n",
    "    true_rows, false_rows = [], []\n",
    "    for row in Data:\n",
    "        if question.match(row):\n",
    "            true_rows.append(row)\n",
    "        else:\n",
    "            false_rows.append(row)\n",
    "    return true_rows, false_rows\n",
    "\n",
    "def gini(Data):\n",
    "    counts = class_counts(Data)\n",
    "    impurity = 1\n",
    "    for lbl in counts:\n",
    "        prob_of_lbl = counts[lbl] / float(len(Data))\n",
    "        impurity -= prob_of_lbl**2\n",
    "    return impurity\n",
    "\n",
    "def info_gain(left, right, current_uncertainty):\n",
    "    p = float(len(left)) / (len(left) + len(right))\n",
    "    return current_uncertainty - p*gini(left) - (1-p)*gini(right)\n",
    "\n",
    "def find_best_split(Data):\n",
    "    best_gain = 0\n",
    "    best_question = None\n",
    "    current_uncertainty = gini(Data)\n",
    "    n_features = len(Data[0]) - 1\n",
    "    for col in range(n_features):\n",
    "        values = unique_vals(Data, col)\n",
    "        for val in values:\n",
    "            question = Question(col, val)\n",
    "            true_rows, false_rows = partition(Data, question)\n",
    "            if len(true_rows) == 0 or len(false_rows) == 0:\n",
    "                continue\n",
    "            gain = info_gain(true_rows, false_rows, current_uncertainty)\n",
    "            if gain > best_gain:\n",
    "                best_gain, best_question = gain, question\n",
    "    return best_gain, best_question\n",
    "\n",
    "class Leaf:\n",
    "    def __init__(self, Data):\n",
    "        self.predictions = class_counts(Data)\n",
    "\n",
    "class Decision_Node:\n",
    "    def __init__(self, question, true_branch, false_branch):\n",
    "        self.question = question\n",
    "        self.true_branch = true_branch\n",
    "        self.false_branch = false_branch\n",
    "\n",
    "def build_tree(Data):\n",
    "    gain, question = find_best_split(Data)\n",
    "    if gain == 0:\n",
    "        return Leaf(Data)\n",
    "    true_rows, false_rows = partition(Data, question)\n",
    "    true_branch = build_tree(true_rows)\n",
    "    false_branch = build_tree(false_rows)\n",
    "    return Decision_Node(question, true_branch, false_branch)\n",
    "\n",
    "def classify(row, node):\n",
    "    if isinstance(node, Leaf):\n",
    "        return node.predictions\n",
    "    if node.question.match(row):\n",
    "        return classify(row, node.true_branch)\n",
    "    else:\n",
    "        return classify(row, node.false_branch)\n",
    "\n",
    "def print_leaf(counts):\n",
    "    total = sum(counts.values())*1.0\n",
    "    probs = {}\n",
    "    for lbl in counts.keys():\n",
    "        probs[lbl] = str(int(counts[lbl]/total * 100)) + \"%\"\n",
    "    return probs\n",
    "\n",
    "\n",
    "# --- Main Execution: Build, Save, Load, and Predict ---\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    # 1. Build the tree from your training data\n",
    "    print(\"Building the decision tree...\")\n",
    "    dt_model_final = build_tree(training_data)\n",
    "    print(\"Tree built successfully.\")\n",
    "\n",
    "    # 2. Save the trained tree object using pickle\n",
    "    model_filename = 'models/custom_decision_tree.pkl'\n",
    "    with open(model_filename, 'wb') as file:\n",
    "        pickle.dump(dt_model_final, file)\n",
    "    print(f\"Custom tree model saved to {model_filename}\")\n",
    "\n",
    "    # 3. Load the model back from the file (to test it)\n",
    "    with open(model_filename, 'rb') as file:\n",
    "        loaded_model = pickle.load(file)\n",
    "    print(\"Model loaded successfully from file.\")\n",
    "\n",
    "    # 4. Use the LOADED model to make a prediction\n",
    "    print(\"\\n--- Making a prediction with the loaded model ---\")\n",
    "    state = \"Bihar\"\n",
    "    district = \"Patna\"\n",
    "    season = \"Kharif\"\n",
    "    testing_row = [state, district, season]\n",
    "    \n",
    "    # Use the loaded_model variable here\n",
    "    prediction_dict = print_leaf(classify(testing_row, loaded_model))\n",
    "\n",
    "    # Display predictions\n",
    "    print(f\"Prediction for input: {testing_row}\")\n",
    "    for key, value in prediction_dict.items():\n",
    "        print(f\"  {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cde8b2f-55fd-49df-82b3-30b95cf0b23b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
